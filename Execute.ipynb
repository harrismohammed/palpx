{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the necessary Libraries required to run this program\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import operator\n",
    "\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us remove all the HTML Tags to obtain a much Clearer Text\n",
    "\n",
    "def striphtml(data):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', str(data))\n",
    "    cleanr = re.compile(', ')\n",
    "    cleantext = re.sub(cleanr, ',', str(cleantext))\n",
    "    cleanr = re.compile('\\'')\n",
    "    cleantext = re.sub(cleanr, '', str(cleantext))\n",
    "    cleanr = re.compile('\\n,')\n",
    "    cleantext = re.sub(cleanr, ' ', str(cleantext))\n",
    "    \n",
    "    return cleantext\n",
    "\n",
    "def find_answer (sentences, question):\n",
    "    \n",
    "    ## By searching through the article we can find where the context related to the Question is present\n",
    "    scores = []\n",
    "    index = []\n",
    "\n",
    "    for i in tqdm(range(len(sentences))) :\n",
    "        score = fuzz.partial_ratio(question, sentences[i])\n",
    "        scores.append(score)\n",
    "        index.append(i)\n",
    "\n",
    "    dictionary_scores = dict(zip(index, scores))\n",
    "\n",
    "    probable_answer_index = max(dictionary_scores.items(), key=operator.itemgetter(1))[0]\n",
    "    score = dictionary_scores[probable_answer_index]\n",
    "    \n",
    "    context = []\n",
    "    \n",
    "    for i in range(probable_answer_index-2, probable_answer_index+2):\n",
    "        context.append(sentences[i])\n",
    "    \n",
    "    imp_word = []\n",
    "    \n",
    "    nlp = spacy.load(\"en\")\n",
    "    doc = nlp(question)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            imp_word.append(token.text)\n",
    "        elif token.dep_ == 'obj' or (token.dep_ == 'dobj') or (token.dep_ == 'iobj') or (token.dep_ == 'pobj'):\n",
    "            imp_word.append(token.text)\n",
    "        elif (token.dep_ == 'subj') or (token.dep_ == 'nsubj') or (token.dep_ == 'nsubjpass') or (token.dep_ == 'csubj') or (token.dep_ == 'csubjpass') :\n",
    "            imp_word.append(token.text)\n",
    "    \n",
    "    key_phrase = ' '.join(imp_word)\n",
    "    \n",
    "    \n",
    "    for sentence in context :\n",
    "        score_2 = fuzz.token_set_ratio(sentence, key_phrase)\n",
    "        \n",
    "        if score_2 >= 50:\n",
    "            print(sentence)\n",
    "            print(\"Score : {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter from where you need to Extract the Article! : https://en.wikipedia.org/wiki/R2-D2\n"
     ]
    }
   ],
   "source": [
    "## The link for the Wikipedia page I webscraped - https://en.wikipedia.org/wiki/R2-D2 \n",
    "## page_url = \"https://en.wikipedia.org/wiki/R2-D2\"\n",
    "\n",
    "page_url = input(\"Enter from where you need to Extract the Article! : \")\n",
    "\n",
    "page = requests.get(page_url)\n",
    "\n",
    "## Let us extract all the Text Data - to understand better Refer README file\n",
    "soup = BeautifulSoup(page.text)\n",
    "text_file = soup.find_all('p')\n",
    "\n",
    "data = striphtml(text_file)\n",
    "\n",
    "sentences = tokenize.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any question related to the article: When was R2-D2 inducted into the Robot Hall of Fame?\n"
     ]
    }
   ],
   "source": [
    "## Lets search for Questions based on Article for Answers\n",
    "question = input(\"Enter any question related to the article: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a43baf0e0194a20ab4a5bd735701750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[34] R2-D2 was inducted into the Robot Hall of Fame in 2003.\n",
      "Score : 83\n"
     ]
    }
   ],
   "source": [
    "find_answer(sentences, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
